{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ce9302f-1357-49c6-99c1-b63f62d8a2e3",
   "metadata": {},
   "source": [
    "# üß™ Scraping Test - Pipeline de scraping (√©tape 1)\n",
    "\n",
    "Ce notebook a pour objectif de tester le pipeline de scraping sur un √©chantillon de produits depuis eBay.\n",
    "\n",
    "üéØ **Objectif** :\n",
    "- Identifier les balises HTML utiles\n",
    "- Tester la r√©cup√©ration des informations (titre, prix, lien)\n",
    "- √âviter la surcharge m√©moire, disque et processeur\n",
    "- Valider la faisabilit√© du scraping\n",
    "\n",
    "üîÑ **Pipeline de scraping (r√©sum√©)** :\n",
    "1. D√©finir les sites √† scraper\n",
    "2. Inspecter la structure HTML des pages\n",
    "3. Identifier les s√©lecteurs (balises CSS/HTML)\n",
    "4. Automatiser avec `requests` et `BeautifulSoup`\n",
    "5. Limiter √† quelques r√©sultats (`limit=5`)\n",
    "6. Ne pas stocker localement pour ce test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd673f8e-a0a0-4d7d-b5ff-be908ad81735",
   "metadata": {},
   "source": [
    "## IMPORTAION BIBLIOTHEQUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae3eb36-4db3-43fd-b019-4c3113e1249b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üì¶ Installer toutes les biblioth√®ques n√©cessaires\n",
    "#!pip install tweepy pandas beautifulsoup4 requests lxml snscrape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56458748-858b-4be2-b63e-a83e1a1fc0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import snscrape.modules.twitter as sntwitter\n",
    "import re\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8125025c-0936-4faa-a70a-7f0c75166c7b",
   "metadata": {},
   "source": [
    "## generation des csv de scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0777ba3-b7b1-4b78-ba84-e9a568f7ef28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "# Liste pour suivre les fichiers sauvegard√©s\n",
    "_saved_files = []\n",
    "\n",
    "def save_dataset(df, site_name, final=False):\n",
    "    \"\"\"\n",
    "    Sauvegarde les donn√©es dans un fichier CSV :\n",
    "    - Si final=True : fichier 'data/final_<site>.csv' (suivi par Git)\n",
    "    - Sinon : fichier 'data/<site>_<timestamp>.csv' (ignor√© par Git)\n",
    "\n",
    "    Ajoute automatiquement le fichier √† la liste des sauvegardes (_saved_files).\n",
    "    \"\"\"\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "    if final:\n",
    "        filename = f\"data/final_{site_name}.csv\"\n",
    "    else:\n",
    "        now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        filename = f\"data/{site_name}_{now}.csv\"\n",
    "\n",
    "    df.to_csv(filename, index=False)\n",
    "    _saved_files.append(filename)\n",
    "    print(f\"‚úÖ Donn√©es sauvegard√©es dans : {filename}\")\n",
    "\n",
    "def check_final_save_required(site_name):\n",
    "    \"\"\"\n",
    "    Affiche un avertissement si aucun fichier final_<site>.csv n'a √©t√© sauvegard√©.\n",
    "    \"\"\"\n",
    "    expected = f\"data/final_{site_name}.csv\"\n",
    "    if expected not in _saved_files:\n",
    "        print(f\"‚ö†Ô∏è Attention : aucune sauvegarde finale d√©tect√©e pour {site_name} !\")\n",
    "        print(f\"üëâ Pense √† appeler : save_dataset(df, site_name='{site_name}', final=True)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee75931d-15cb-4b43-8440-3cf61e68c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Scraping\n",
    "# ... ton code ...\n",
    "\n",
    "# 2. Sauvegarde automatique ignor√©e par Git\n",
    "#save_dataset(df, site_name=\"reddit\")\n",
    "\n",
    "# 3. V√©rification en fin de script\n",
    "#check_final_save_required(\"reddit\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad0f553-cc61-4a0c-9a4c-7804bcbda48d",
   "metadata": {},
   "source": [
    "## TWITTER SCRAPIING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5205a81-f07e-452e-ad79-987cdecdc790",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tweet ID: 1926950633413791882\n",
      "Date: 2025-05-26 10:36:46+00:00\n",
      "Texte: No one‚Äôs safe when ChatGPT reads the zodiac like this.\n",
      "Your sign‚Äôs brutally honest truth ‚Äî oddly accurate and way too personal.\n",
      "Save this one üìå &amp; RT if it‚Äôs you!\n",
      "Follow @forbelite for more AI insights.\n",
      "\n",
      "#AI #ChatGPT #Tech #Forbelite https://t.co/60BBgeDnlM\n",
      "Likes: 0, Retweets: 0\n",
      "--------------------------------------------------\n",
      "Tweet ID: 1926950509061062985\n",
      "Date: 2025-05-26 10:36:17+00:00\n",
      "Texte: reading #Grok3 #AI„Ç§„É©„Çπ„Éà #AIArtCommuity #aigeneratedart #aigenerated #AIArtwork #AIArtGallery #AIartists #beauty #photography #AIbeauty #AIart  #ÊñáÈùí #shavedhead #BeautifulBody #AiartÔ∏è #AI„Ç§„Ç±„É°„É≥ #AIArtistCommunity https://t.co/z8AQbut6kH\n",
      "Likes: 0, Retweets: 0\n",
      "--------------------------------------------------\n",
      "Tweet ID: 1926950447417270341\n",
      "Date: 2025-05-26 10:36:02+00:00\n",
      "Texte: Breaking News: AI model Claude 3.5 outperforms GPT-4 in reasoning tasks, claims Anthropic. Released today, it excels in coding and math. #AI #Tech\n",
      "Likes: 0, Retweets: 0\n",
      "--------------------------------------------------\n",
      "Tweet ID: 1926950278776910044\n",
      "Date: 2025-05-26 10:35:22+00:00\n",
      "Texte: The first #battle of controlled robots - like in \"Living Steel\" - took place in China.\n",
      "\n",
      "It's time for the #UFC to step up their game.\n",
      "\n",
      "#robotfight #Robotics #robots #cobot #humanoid #robotech #robotgirl #technology #TechRevolution #tech #Engineering \n",
      "\n",
      "@fogle_shane @KanezaDiane https://t.co/k91e89vbA5\n",
      "Likes: 0, Retweets: 0\n",
      "--------------------------------------------------\n",
      "Tweet ID: 1926950191212491169\n",
      "Date: 2025-05-26 10:35:01+00:00\n",
      "Texte: Check out our exclusive range of products! üõçÔ∏è Visit our store today and find your perfect fit with our stylish collection. #Shopping #Fashion\n",
      "Likes: 0, Retweets: 0\n",
      "--------------------------------------------------\n",
      "Tweet ID: 1926949948454486438\n",
      "Date: 2025-05-26 10:34:03+00:00\n",
      "Texte: First Aid Beauty KP Bump Eraser Body Scrub with 10% AHA - Body Exfoliant for Keratosis Pilaris 226g  for  $30.00\n",
      "\n",
      "https://t.co/PfG4abWlyD\n",
      "\n",
      "#Beauty https://t.co/VsKmfU2Imt\n",
      "Likes: 0, Retweets: 0\n",
      "--------------------------------------------------\n",
      "Tweet ID: 1926949857501028490\n",
      "Date: 2025-05-26 10:33:41+00:00\n",
      "Texte: From sabzi mandi to high-end luxury stores, our good old Indian jhola just got a ‚Çπ4K glow-up!\n",
      "What's your take on this?\n",
      "@Puebco \n",
      "#MarketingQuake #Culture #Tradition #Global #Luxury #Identity #Fashion #Viral #Buzz #Trending \n",
      "\n",
      "(Luxury, Brands, Tradition, Marketing¬†Quake) https://t.co/U5aytzlMFr\n",
      "Likes: 0, Retweets: 0\n",
      "--------------------------------------------------\n",
      "Tweet ID: 1926949832695927098\n",
      "Date: 2025-05-26 10:33:35+00:00\n",
      "Texte: @Sxne19iv2 Him and barbiedoll your left flank is about to be #food üò≠üò≠\n",
      "Likes: 1, Retweets: 0\n",
      "--------------------------------------------------\n",
      "Tweet ID: 1926949830695240041\n",
      "Date: 2025-05-26 10:33:35+00:00\n",
      "Texte: bridge #Grok3 #AI„Ç§„É©„Çπ„Éà #AIArtCommuity #aigeneratedart #aigenerated #AIArtwork #AIArtGallery #AIartists #beauty #photography #AIbeauty #AIart  #ÊñáÈùí #shavedhead #BeautifulBody #AiartÔ∏è #AI„Ç§„Ç±„É°„É≥ #AIArtistCommunity https://t.co/pXkGcW41u0\n",
      "Likes: 0, Retweets: 0\n",
      "--------------------------------------------------\n",
      "Tweet ID: 1926949684377190813\n",
      "Date: 2025-05-26 10:33:00+00:00\n",
      "Texte: Elektros dubs lithium the ‚Äúliquid gold‚Äù of EVs focusing on improved lithium #extraction, rare-earth processing &amp; scalable energy storage to meet booming global electric mobility demands. \n",
      "\n",
      "#ElectricVehicles #EnergyForTomorrow #storage #RareEarths #Automotive #electricity #tech https://t.co/UVAUtDLH7c\n",
      "Likes: 0, Retweets: 0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tweepy\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "BEARER_TOKEN = os.getenv(\"BEARER_TOKEN\")\n",
    "\n",
    "# V√©rification du chargement du token\n",
    "if not BEARER_TOKEN:\n",
    "    raise ValueError(\"Le token d'acc√®s n'a pas √©t√© trouv√©. V√©rifie ton fichier .env\")\n",
    "\n",
    "# Connexion √† l'API\n",
    "client = tweepy.Client(bearer_token=BEARER_TOKEN)\n",
    "\n",
    "# Requ√™te\n",
    "query = \"(#beauty OR #fashion OR #tech OR #food) -is:retweet lang:en\"\n",
    "\n",
    "# Appel API\n",
    "tweets = client.search_recent_tweets(\n",
    "    query=query,\n",
    "    max_results=10,\n",
    "    tweet_fields=['public_metrics', 'created_at']\n",
    ")\n",
    "\n",
    "# Affichage des r√©sultats\n",
    "for tweet in tweets.data:\n",
    "    print(f\"Tweet ID: {tweet.id}\")\n",
    "    print(f\"Date: {tweet.created_at}\")\n",
    "    print(f\"Texte: {tweet.text}\")\n",
    "    print(f\"Likes: {tweet.public_metrics['like_count']}, Retweets: {tweet.public_metrics['retweet_count']}\")\n",
    "    print(\"-\" * 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47deace8-264b-46e6-892f-70aa8ff6bfc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (Custom)",
   "language": "python",
   "name": "python313"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
